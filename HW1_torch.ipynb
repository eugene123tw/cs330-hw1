{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW1_torch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMu0epZ7zAdGOAh0+oJYd/+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eugene123tw/cs330-hw1/blob/master/HW1_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQF_A-QXK98n",
        "colab_type": "code",
        "outputId": "83ff7886-b8ed-4d04-f734-54a7622f5571",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# Downlaod Omniglot \n",
        "workspace_dir = '.'\n",
        "!gdown --id 1aBacYkuigdlKExME-kgxqworbdd8Zixg --output \"{workspace_dir}/omniglot_resized.zip\"\n",
        "!unzip -q omniglot_resized"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1aBacYkuigdlKExME-kgxqworbdd8Zixg\n",
            "To: /content/omniglot_resized.zip\n",
            "13.0MB [00:00, 35.7MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmdQh0OMLDrY",
        "colab_type": "code",
        "outputId": "10f92fc9-c93e-415e-c47e-fb1b52706ac3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime â†’ \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Apr 11 09:22:14 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URsMk0fXYrMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "cuda = torch.device('cuda')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oUIO3LbLGAo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_images(paths, labels, nb_samples=None, shuffle=True):\n",
        "  \"\"\"\n",
        "  Takes a set of character folders and labels and returns paths to image files\n",
        "  paired with labels.\n",
        "  Args:\n",
        "      paths: A list of character folders\n",
        "      labels: List or numpy array of same length as paths\n",
        "      nb_samples: Number of images to retrieve per character\n",
        "  Returns:\n",
        "      List of (label, image_path) tuples\n",
        "  \"\"\"\n",
        "  if nb_samples is not None:\n",
        "    sampler = lambda x: random.sample(x, nb_samples)\n",
        "  else:\n",
        "    sampler = lambda x: x\n",
        "  images_labels = [(i, os.path.join(path, image))\n",
        "                   for i, path in zip(labels, paths)\n",
        "                   for image in sampler(os.listdir(path))]\n",
        "  if shuffle:\n",
        "    random.shuffle(images_labels)\n",
        "  return images_labels\n",
        "\n",
        "\n",
        "def image_file_to_array(filename, dim_input):\n",
        "  \"\"\"\n",
        "  Takes an image path and returns numpy array\n",
        "  Args:\n",
        "      filename: Image filename\n",
        "      dim_input: Flattened shape of image\n",
        "  Returns:\n",
        "      1 channel image\n",
        "  \"\"\"\n",
        "  image = imread(filename)\n",
        "  image = image.reshape([dim_input])\n",
        "  image = image.astype(np.float32) / 255.0\n",
        "  image = 1.0 - image\n",
        "  return image\n",
        "\n",
        "\n",
        "class DataGenerator(object):\n",
        "  \"\"\"\n",
        "  Data Generator capable of generating batches of Omniglot data.\n",
        "  A \"class\" is considered a class of omniglot digits.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, num_classes, num_samples_per_class, config={}):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        num_classes: Number of classes for classification (K-way)\n",
        "        num_samples_per_class: num samples to generate per class in one batch\n",
        "        batch_size: size of meta batch size (e.g. number of functions)\n",
        "    \"\"\"\n",
        "    self.num_samples_per_class = num_samples_per_class\n",
        "    self.num_classes = num_classes\n",
        "\n",
        "    data_folder = config.get('data_folder', './omniglot_resized')\n",
        "    self.img_size = config.get('img_size', (28, 28))\n",
        "\n",
        "    self.dim_input = np.prod(self.img_size)\n",
        "    self.dim_output = self.num_classes\n",
        "\n",
        "    character_folders = [os.path.join(data_folder, family, character)\n",
        "                         for family in os.listdir(data_folder)\n",
        "                         if os.path.isdir(os.path.join(data_folder, family))\n",
        "                         for character in os.listdir(os.path.join(data_folder, family))\n",
        "                         if os.path.isdir(os.path.join(data_folder, family, character))]\n",
        "\n",
        "    random.seed(1)\n",
        "    random.shuffle(character_folders)\n",
        "    num_val = 100\n",
        "    num_train = 1100\n",
        "    self.metatrain_character_folders = character_folders[: num_train]\n",
        "    self.metaval_character_folders = character_folders[\n",
        "                                     num_train:num_train + num_val]\n",
        "    self.metatest_character_folders = character_folders[\n",
        "                                      num_train + num_val:]\n",
        "\n",
        "  def sample_batch(self, batch_type, batch_size):\n",
        "    \"\"\"\n",
        "    Samples a batch for training, validation, or testing\n",
        "    Args:\n",
        "        batch_type: train/val/test\n",
        "    Returns:\n",
        "        A a tuple of (1) Image batch and (2) Label batch where\n",
        "        image batch has shape [B, K, N, 784] and label batch has shape [B, K, N, N]\n",
        "        where B is batch size, K is number of samples per class, N is number of classes\n",
        "    \"\"\"\n",
        "    if batch_type == \"train\":\n",
        "      folders = self.metatrain_character_folders\n",
        "    elif batch_type == \"val\":\n",
        "      folders = self.metaval_character_folders\n",
        "    else:\n",
        "      folders = self.metatest_character_folders\n",
        "\n",
        "    #############################\n",
        "    #### YOUR CODE GOES HERE ####\n",
        "    # Initialise array for storage\n",
        "    all_image_batches = np.zeros(\n",
        "      (batch_size, self.num_samples_per_class, self.num_classes, 784)\n",
        "    )\n",
        "\n",
        "    all_label_batches = np.zeros(\n",
        "      (batch_size, self.num_samples_per_class, self.num_classes, self.num_classes)\n",
        "    )\n",
        "\n",
        "    for b in range(batch_size):  # sample mini batch of tasks\n",
        "      sampled_paths = np.random.choice(folders, self.num_classes)\n",
        "      images_labels = get_images(\n",
        "        sampled_paths, np.eye(self.num_classes), self.num_samples_per_class, False)\n",
        "\n",
        "      test_images, test_labels = [], []\n",
        "      train_images, train_labels = [], []\n",
        "      for i, (y_vector, image_path) in enumerate(images_labels):\n",
        "        image = image_file_to_array(image_path, 784)\n",
        "        if i % self.num_samples_per_class == 0:\n",
        "          test_images.append(image)\n",
        "          test_labels.append(y_vector)\n",
        "        else:\n",
        "          train_images.append(image)\n",
        "          train_labels.append(y_vector)\n",
        "\n",
        "      ts_indices = np.random.permutation(range(len(test_images)))\n",
        "      test_images = np.array(test_images)[ts_indices]\n",
        "      test_labels = np.array(test_labels)[ts_indices]\n",
        "\n",
        "      tr_indices = np.random.permutation(range(len(train_images)))\n",
        "      train_images = np.array(train_images)[tr_indices]\n",
        "      train_labels = np.array(train_labels)[tr_indices]\n",
        "\n",
        "      all_image_batches[b, ...] = np.vstack((train_images, test_images)).reshape(\n",
        "        self.num_samples_per_class, self.num_classes, -1\n",
        "      )\n",
        "      all_label_batches[b, ...] = np.vstack((train_labels, test_labels)).reshape(\n",
        "        self.num_samples_per_class, self.num_classes, -1)\n",
        "    #############################\n",
        "\n",
        "    return all_image_batches, all_label_batches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wqaX6u_UtjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MANN(nn.Module):\n",
        "  def __init__(self, num_classes):\n",
        "    super(MANN, self).__init__()\n",
        "    # The first axis is the sequence itself, \n",
        "    # the second indexes instances in the mini-batch, \n",
        "    # and the third indexes elements of the input\n",
        "    self.N = num_classes\n",
        "    self.layer1 = nn.LSTM(784 + num_classes, 128)\n",
        "    self.layer2 = nn.LSTM(128, num_classes)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    \"\"\" x is a tensor concatenated images and labels: [(K + 1)*N, B, 784 + N] \"\"\"\n",
        "    # Hint: Passing zeros, not the ground truth labels for the final N examples.\n",
        "    #       Remember we should mask the true labels of test set. \n",
        "    #       Otherwise, our model will learn the pattern and we don't want this.\n",
        "    x[-N:, :, -N:] = 0\n",
        "    out, _ = self.layer1(x)\n",
        "    out, _ = self.layer2(out)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgK2TaSRag5t",
        "colab_type": "text"
      },
      "source": [
        "# Start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGQCLaZZXdqs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser(description='Process some flags.')\n",
        "\n",
        "parser.add_argument('--num_classes', type=int, default=2, help='number of classes used in classification (e.g. 5-way classification).')\n",
        "\n",
        "parser.add_argument('--num_samples', type=int, default=1, help='number of examples used for inner gradient update (K for K-shot learning).')\n",
        "\n",
        "parser.add_argument('--meta_batch_size', type=int, default=4, help='Number of N-way classification tasks per batch')\n",
        "\n",
        "parser.add_argument('--data_root', type=str, default= 'omniglot_resized', help='data folder root')\n",
        "\n",
        "FLAGS = parser.parse_args(args=[])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l94BhW5xa2ZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "net = MANN(num_classes=FLAGS.num_classes)\n",
        "net = net.cuda().train()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74ZfpMnhYLYe",
        "colab_type": "code",
        "outputId": "e5df0e6f-df05-4c16-ff96-99b6f4c39d62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data_generator = DataGenerator(\n",
        "  FLAGS.num_classes,\n",
        "  FLAGS.num_samples + 1,\n",
        "  {'data_folder': FLAGS.data_root}\n",
        ")\n",
        "\n",
        "for step in range(50000):\n",
        "  net = net.cuda().train()\n",
        "  images, labels = data_generator.sample_batch('train', FLAGS.meta_batch_size)\n",
        "  B, K_plus_1, N, _ = images.shape\n",
        "\n",
        "  images = images.reshape((B, K_plus_1 * N, -1))\n",
        "  labels = labels.reshape((B, K_plus_1 * N, N))\n",
        "\n",
        "  images = torch.tensor(images, device=cuda)\n",
        "  labels = torch.tensor(labels, device=cuda)\n",
        "\n",
        "  optimizer.zero_grad()   # zero the gradient buffers\n",
        "  input_tensor = torch.tensor(torch.cat([images, labels], dim=2).transpose(0, 1), device=cuda)\n",
        "  logits = net(input_tensor.float()).transpose(0, 1)\n",
        "  loss = criterion(logits[:, -N:], labels[:, -N:])\n",
        "  loss.backward()\n",
        "  optimizer.step()    \n",
        "\n",
        "  if step % 100 == 0:\n",
        "    with torch.no_grad():\n",
        "      print(\"*\" * 5 + \"Iter \" + str(step) + \"*\" * 5)\n",
        "      net.eval()\n",
        "      images, labels = data_generator.sample_batch('test', 100)\n",
        "      B, K_plus_1, N, _ = images.shape\n",
        "\n",
        "      images = images.reshape((B, K_plus_1 * N, -1))\n",
        "      labels = labels.reshape((B, K_plus_1 * N, N))\n",
        "\n",
        "      images = torch.tensor(images, device=cuda)\n",
        "      labels = torch.tensor(labels, device=cuda)\n",
        "      input_tensor = torch.tensor(torch.cat([images, labels], dim=2).transpose(0, 1), device=cuda)\n",
        "      \n",
        "      logits = net(input_tensor.float()).transpose(0, 1)\n",
        "      test_loss = criterion(logits[:, -N:], labels[:, -N:])\n",
        "      test_loss_value = test_loss.detach().cpu().numpy()\n",
        "\n",
        "      loss_value = loss.detach().cpu().numpy()\n",
        "\n",
        "      print(\"Train Loss:\", loss_value, \"Test Loss:\", test_loss_value)\n",
        "      logits = logits.reshape(\n",
        "        -1, FLAGS.num_samples + 1,\n",
        "        FLAGS.num_classes, FLAGS.num_classes)\n",
        "      \n",
        "      labels = labels.reshape((B, K_plus_1, N, N))\n",
        "\n",
        "      logits = logits[:, -1, :, :].argmax(2)\n",
        "      labels = labels[:, -1, :, :].argmax(2)\n",
        "      accuracy = (1.0 * (logits == labels)).mean()\n",
        "      print(\"Test Accuracy\", accuracy.detach().cpu().numpy())\n",
        "      "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*****Iter 0*****\n",
            "Train Loss: 0.6951493800152093 Test Loss: 0.6969771106425198\n",
            "Test Accuracy 0.49499997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*****Iter 100*****\n",
            "Train Loss: 0.6892036946032931 Test Loss: 0.693138021435661\n",
            "Test Accuracy 0.53\n",
            "*****Iter 200*****\n",
            "Train Loss: 0.6933114789453612 Test Loss: 0.6932087412758224\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 300*****\n",
            "Train Loss: 0.6931022507160378 Test Loss: 0.6933350185924935\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 400*****\n",
            "Train Loss: 0.693324089134876 Test Loss: 0.6930003540740101\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 500*****\n",
            "Train Loss: 0.6930463697607792 Test Loss: 0.6931522944452025\n",
            "Test Accuracy 0.51\n",
            "*****Iter 600*****\n",
            "Train Loss: 0.6931016560645276 Test Loss: 0.6931367304062639\n",
            "Test Accuracy 0.53999996\n",
            "*****Iter 700*****\n",
            "Train Loss: 0.6931926283928078 Test Loss: 0.693123864303332\n",
            "Test Accuracy 0.505\n",
            "*****Iter 800*****\n",
            "Train Loss: 0.6933683437381433 Test Loss: 0.6931942108202747\n",
            "Test Accuracy 0.5\n",
            "*****Iter 900*****\n",
            "Train Loss: 0.6931490787656713 Test Loss: 0.6931178088194094\n",
            "Test Accuracy 0.5\n",
            "*****Iter 1000*****\n",
            "Train Loss: 0.693160137974326 Test Loss: 0.6931552303142718\n",
            "Test Accuracy 0.5\n",
            "*****Iter 1100*****\n",
            "Train Loss: 0.6931548871250632 Test Loss: 0.6931317053439142\n",
            "Test Accuracy 0.5\n",
            "*****Iter 1200*****\n",
            "Train Loss: 0.693144048196442 Test Loss: 0.6931134375143821\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 1300*****\n",
            "Train Loss: 0.6931535797878364 Test Loss: 0.6931592771953385\n",
            "Test Accuracy 0.5\n",
            "*****Iter 1400*****\n",
            "Train Loss: 0.6931514150500357 Test Loss: 0.6931455196439084\n",
            "Test Accuracy 0.5\n",
            "*****Iter 1500*****\n",
            "Train Loss: 0.6931588937960704 Test Loss: 0.6931942369618909\n",
            "Test Accuracy 0.5\n",
            "*****Iter 1600*****\n",
            "Train Loss: 0.693146098993821 Test Loss: 0.6931534730303786\n",
            "Test Accuracy 0.5\n",
            "*****Iter 1700*****\n",
            "Train Loss: 0.6931592234190631 Test Loss: 0.693148547203209\n",
            "Test Accuracy 0.5\n",
            "*****Iter 1800*****\n",
            "Train Loss: 0.6931118487139251 Test Loss: 0.6931520384819286\n",
            "Test Accuracy 0.5\n",
            "*****Iter 1900*****\n",
            "Train Loss: 0.6931472611237668 Test Loss: 0.6932172882651116\n",
            "Test Accuracy 0.5\n",
            "*****Iter 2000*****\n",
            "Train Loss: 0.6931468081289172 Test Loss: 0.6931523582403535\n",
            "Test Accuracy 0.5\n",
            "*****Iter 2100*****\n",
            "Train Loss: 0.6931454149358149 Test Loss: 0.6931351177636919\n",
            "Test Accuracy 0.5\n",
            "*****Iter 2200*****\n",
            "Train Loss: 0.6931983258103261 Test Loss: 0.6931143416552021\n",
            "Test Accuracy 0.5\n",
            "*****Iter 2300*****\n",
            "Train Loss: 0.6931468881621334 Test Loss: 0.6931389459401329\n",
            "Test Accuracy 0.5\n",
            "*****Iter 2400*****\n",
            "Train Loss: 0.6931480637910976 Test Loss: 0.6931098165848831\n",
            "Test Accuracy 0.5\n",
            "*****Iter 2500*****\n",
            "Train Loss: 0.693152390415662 Test Loss: 0.69314484441669\n",
            "Test Accuracy 0.5\n",
            "*****Iter 2600*****\n",
            "Train Loss: 0.6931422063120234 Test Loss: 0.6931445574241228\n",
            "Test Accuracy 0.5\n",
            "*****Iter 2700*****\n",
            "Train Loss: 0.6931450534362041 Test Loss: 0.6931258121223988\n",
            "Test Accuracy 0.5\n",
            "*****Iter 2800*****\n",
            "Train Loss: 0.6931483708993169 Test Loss: 0.693148054611083\n",
            "Test Accuracy 0.5\n",
            "*****Iter 2900*****\n",
            "Train Loss: 0.6931493037809293 Test Loss: 0.6931491187241184\n",
            "Test Accuracy 0.5\n",
            "*****Iter 3000*****\n",
            "Train Loss: 0.693147105700257 Test Loss: 0.6931412877485053\n",
            "Test Accuracy 0.5\n",
            "*****Iter 3100*****\n",
            "Train Loss: 0.6931457492972177 Test Loss: 0.6931449369841286\n",
            "Test Accuracy 0.5\n",
            "*****Iter 3200*****\n",
            "Train Loss: 0.6931469020904323 Test Loss: 0.6931519758314959\n",
            "Test Accuracy 0.5\n",
            "*****Iter 3300*****\n",
            "Train Loss: 0.6931469456063928 Test Loss: 0.693145121577284\n",
            "Test Accuracy 0.5\n",
            "*****Iter 3400*****\n",
            "Train Loss: 0.6931490724292745 Test Loss: 0.6931452771568972\n",
            "Test Accuracy 0.5\n",
            "*****Iter 3500*****\n",
            "Train Loss: 0.6931470049468434 Test Loss: 0.6931523501266447\n",
            "Test Accuracy 0.5\n",
            "*****Iter 3600*****\n",
            "Train Loss: 0.6931489168928409 Test Loss: 0.6931483871338953\n",
            "Test Accuracy 0.5\n",
            "*****Iter 3700*****\n",
            "Train Loss: 0.6931472907180734 Test Loss: 0.6931455099586438\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 3800*****\n",
            "Train Loss: 0.6934825504054718 Test Loss: 0.6931468561471636\n",
            "Test Accuracy 0.5\n",
            "*****Iter 3900*****\n",
            "Train Loss: 0.6932064660875952 Test Loss: 0.6928437081905428\n",
            "Test Accuracy 0.505\n",
            "*****Iter 4000*****\n",
            "Train Loss: 0.6931843685640147 Test Loss: 0.6931482784356415\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 4100*****\n",
            "Train Loss: 0.6931523061503839 Test Loss: 0.6931519157825192\n",
            "Test Accuracy 0.5\n",
            "*****Iter 4200*****\n",
            "Train Loss: 0.6931422091659312 Test Loss: 0.6931466643620169\n",
            "Test Accuracy 0.5\n",
            "*****Iter 4300*****\n",
            "Train Loss: 0.693153029641663 Test Loss: 0.6931467697855657\n",
            "Test Accuracy 0.5\n",
            "*****Iter 4400*****\n",
            "Train Loss: 0.6931020594170689 Test Loss: 0.6931357030803709\n",
            "Test Accuracy 0.5\n",
            "*****Iter 4500*****\n",
            "Train Loss: 0.6931514020877423 Test Loss: 0.6931475244631556\n",
            "Test Accuracy 0.5\n",
            "*****Iter 4600*****\n",
            "Train Loss: 0.693146967796564 Test Loss: 0.6931465857124909\n",
            "Test Accuracy 0.5\n",
            "*****Iter 4700*****\n",
            "Train Loss: 0.6931476957422433 Test Loss: 0.6931461864281968\n",
            "Test Accuracy 0.505\n",
            "*****Iter 4800*****\n",
            "Train Loss: 0.6931478868421337 Test Loss: 0.6931460265748831\n",
            "Test Accuracy 0.505\n",
            "*****Iter 4900*****\n",
            "Train Loss: 0.6931453541301705 Test Loss: 0.6931466715214019\n",
            "Test Accuracy 0.5\n",
            "*****Iter 5000*****\n",
            "Train Loss: 0.6931452037725584 Test Loss: 0.6931461553032077\n",
            "Test Accuracy 0.505\n",
            "*****Iter 5100*****\n",
            "Train Loss: 0.6931437560683802 Test Loss: 0.6931455971374961\n",
            "Test Accuracy 0.5\n",
            "*****Iter 5200*****\n",
            "Train Loss: 0.6931432742139898 Test Loss: 0.6931484522324513\n",
            "Test Accuracy 0.5\n",
            "*****Iter 5300*****\n",
            "Train Loss: 0.6931385149592526 Test Loss: 0.6931439697141195\n",
            "Test Accuracy 0.505\n",
            "*****Iter 5400*****\n",
            "Train Loss: 0.6931526173653269 Test Loss: 0.693148636401157\n",
            "Test Accuracy 0.48499998\n",
            "*****Iter 5500*****\n",
            "Train Loss: 0.6930958830100833 Test Loss: 0.6930909402768454\n",
            "Test Accuracy 0.51\n",
            "*****Iter 5600*****\n",
            "Train Loss: 0.6932546608970973 Test Loss: 0.69289842706847\n",
            "Test Accuracy 0.5\n",
            "*****Iter 5700*****\n",
            "Train Loss: 0.6931337980442709 Test Loss: 0.6931734463165524\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 5800*****\n",
            "Train Loss: 0.6931518047733849 Test Loss: 0.6931219041730039\n",
            "Test Accuracy 0.525\n",
            "*****Iter 5900*****\n",
            "Train Loss: 0.6932157771413747 Test Loss: 0.6931377415578404\n",
            "Test Accuracy 0.5\n",
            "*****Iter 6000*****\n",
            "Train Loss: 0.6929763756615157 Test Loss: 0.6931108863621616\n",
            "Test Accuracy 0.505\n",
            "*****Iter 6100*****\n",
            "Train Loss: 0.6930865549032816 Test Loss: 0.693037047293111\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 6200*****\n",
            "Train Loss: 0.6924345885979155 Test Loss: 0.691989012694389\n",
            "Test Accuracy 0.5\n",
            "*****Iter 6300*****\n",
            "Train Loss: 0.6931459651284047 Test Loss: 0.6931786196856324\n",
            "Test Accuracy 0.5\n",
            "*****Iter 6400*****\n",
            "Train Loss: 0.6931499432869916 Test Loss: 0.6931413214946051\n",
            "Test Accuracy 0.5\n",
            "*****Iter 6500*****\n",
            "Train Loss: 0.6931567966926977 Test Loss: 0.693162964520617\n",
            "Test Accuracy 0.5\n",
            "*****Iter 6600*****\n",
            "Train Loss: 0.6931145356635238 Test Loss: 0.6931301560941265\n",
            "Test Accuracy 0.5\n",
            "*****Iter 6700*****\n",
            "Train Loss: 0.6931880797285013 Test Loss: 0.6931404089876372\n",
            "Test Accuracy 0.5\n",
            "*****Iter 6800*****\n",
            "Train Loss: 0.6931427749437056 Test Loss: 0.6931461178805884\n",
            "Test Accuracy 0.5\n",
            "*****Iter 6900*****\n",
            "Train Loss: 0.693148075879515 Test Loss: 0.6931264340834923\n",
            "Test Accuracy 0.5\n",
            "*****Iter 7000*****\n",
            "Train Loss: 0.693149689388008 Test Loss: 0.6931405411916234\n",
            "Test Accuracy 0.5\n",
            "*****Iter 7100*****\n",
            "Train Loss: 0.6931488772353678 Test Loss: 0.6931520299215138\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 7200*****\n",
            "Train Loss: 0.6931469298366455 Test Loss: 0.6931487710893495\n",
            "Test Accuracy 0.5\n",
            "*****Iter 7300*****\n",
            "Train Loss: 0.6931513210452174 Test Loss: 0.6931442988368874\n",
            "Test Accuracy 0.5\n",
            "*****Iter 7400*****\n",
            "Train Loss: 0.6931476360661257 Test Loss: 0.6931192057314507\n",
            "Test Accuracy 0.5\n",
            "*****Iter 7500*****\n",
            "Train Loss: 0.693219301602273 Test Loss: 0.6931406498808996\n",
            "Test Accuracy 0.5\n",
            "*****Iter 7600*****\n",
            "Train Loss: 0.6931475875562341 Test Loss: 0.693153252009441\n",
            "Test Accuracy 0.5\n",
            "*****Iter 7700*****\n",
            "Train Loss: 0.6931321195497819 Test Loss: 0.6931342563060162\n",
            "Test Accuracy 0.5\n",
            "*****Iter 7800*****\n",
            "Train Loss: 0.693150030677165 Test Loss: 0.693149238030653\n",
            "Test Accuracy 0.5\n",
            "*****Iter 7900*****\n",
            "Train Loss: 0.6931482159417026 Test Loss: 0.6931437970722051\n",
            "Test Accuracy 0.5\n",
            "*****Iter 8000*****\n",
            "Train Loss: 0.693110781047718 Test Loss: 0.6931490359563969\n",
            "Test Accuracy 0.5\n",
            "*****Iter 8100*****\n",
            "Train Loss: 0.6931615064876944 Test Loss: 0.6931460906605318\n",
            "Test Accuracy 0.5\n",
            "*****Iter 8200*****\n",
            "Train Loss: 0.6931635451573577 Test Loss: 0.6931834542673194\n",
            "Test Accuracy 0.5\n",
            "*****Iter 8300*****\n",
            "Train Loss: 0.6930756469454415 Test Loss: 0.6931496793076123\n",
            "Test Accuracy 0.5\n",
            "*****Iter 8400*****\n",
            "Train Loss: 0.6931548867920583 Test Loss: 0.6931284828705148\n",
            "Test Accuracy 0.5\n",
            "*****Iter 8500*****\n",
            "Train Loss: 0.6931671069231058 Test Loss: 0.692929635539244\n",
            "Test Accuracy 0.5\n",
            "*****Iter 8600*****\n",
            "Train Loss: 0.6928721806485001 Test Loss: 0.6930887190981017\n",
            "Test Accuracy 0.5\n",
            "*****Iter 8700*****\n",
            "Train Loss: 0.6924381086336329 Test Loss: 0.6930087032530033\n",
            "Test Accuracy 0.5\n",
            "*****Iter 8800*****\n",
            "Train Loss: 0.693148544752078 Test Loss: 0.6930676091883377\n",
            "Test Accuracy 0.5\n",
            "*****Iter 8900*****\n",
            "Train Loss: 0.6931378063897569 Test Loss: 0.6931465311846368\n",
            "Test Accuracy 0.5\n",
            "*****Iter 9000*****\n",
            "Train Loss: 0.6931067737202641 Test Loss: 0.6929424457026593\n",
            "Test Accuracy 0.5\n",
            "*****Iter 9100*****\n",
            "Train Loss: 0.6933356834466249 Test Loss: 0.6931689093275387\n",
            "Test Accuracy 0.5\n",
            "*****Iter 9200*****\n",
            "Train Loss: 0.6952799516682853 Test Loss: 0.6950360468546379\n",
            "Test Accuracy 0.51\n",
            "*****Iter 9300*****\n",
            "Train Loss: 0.6679615854458663 Test Loss: 0.6967213762526978\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 9400*****\n",
            "Train Loss: 0.6942341314284416 Test Loss: 0.6926072454583114\n",
            "Test Accuracy 0.505\n",
            "*****Iter 9500*****\n",
            "Train Loss: 0.6940697804636367 Test Loss: 0.688398041838191\n",
            "Test Accuracy 0.5\n",
            "*****Iter 9600*****\n",
            "Train Loss: 0.6884495358329237 Test Loss: 0.6904852138237857\n",
            "Test Accuracy 0.505\n",
            "*****Iter 9700*****\n",
            "Train Loss: 0.6944007528488614 Test Loss: 0.6859342340375254\n",
            "Test Accuracy 0.5\n",
            "*****Iter 9800*****\n",
            "Train Loss: 0.686364273366431 Test Loss: 0.6887980643560618\n",
            "Test Accuracy 0.48499998\n",
            "*****Iter 9900*****\n",
            "Train Loss: 0.6947359735406278 Test Loss: 0.685516349096164\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 10000*****\n",
            "Train Loss: 0.6797066406905605 Test Loss: 0.683747159300506\n",
            "Test Accuracy 0.505\n",
            "*****Iter 10100*****\n",
            "Train Loss: 0.6955775770646022 Test Loss: 0.6781696799617367\n",
            "Test Accuracy 0.505\n",
            "*****Iter 10200*****\n",
            "Train Loss: 0.6716578889160942 Test Loss: 0.673034664733863\n",
            "Test Accuracy 0.5\n",
            "*****Iter 10300*****\n",
            "Train Loss: 0.695687328664846 Test Loss: 0.6758193715523546\n",
            "Test Accuracy 0.48499998\n",
            "*****Iter 10400*****\n",
            "Train Loss: 0.6865570332021447 Test Loss: 0.6825974849102151\n",
            "Test Accuracy 0.505\n",
            "*****Iter 10500*****\n",
            "Train Loss: 0.6820733133067611 Test Loss: 0.6679755261400888\n",
            "Test Accuracy 0.5\n",
            "*****Iter 10600*****\n",
            "Train Loss: 0.7073948999971607 Test Loss: 0.6813210590111729\n",
            "Test Accuracy 0.5\n",
            "*****Iter 10700*****\n",
            "Train Loss: 0.6481591622928953 Test Loss: 0.6667966544322431\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 10800*****\n",
            "Train Loss: 0.7066142398633595 Test Loss: 0.6759471689172507\n",
            "Test Accuracy 0.5\n",
            "*****Iter 10900*****\n",
            "Train Loss: 0.7136393173132474 Test Loss: 0.6732402698882579\n",
            "Test Accuracy 0.48\n",
            "*****Iter 11000*****\n",
            "Train Loss: 0.6394961806756814 Test Loss: 0.673347605392734\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 11100*****\n",
            "Train Loss: 0.7007686791774166 Test Loss: 0.667500456250376\n",
            "Test Accuracy 0.5\n",
            "*****Iter 11200*****\n",
            "Train Loss: 0.6813837293064751 Test Loss: 0.6707962390954892\n",
            "Test Accuracy 0.5\n",
            "*****Iter 11300*****\n",
            "Train Loss: 0.6862957935009764 Test Loss: 0.6725637013733174\n",
            "Test Accuracy 0.51\n",
            "*****Iter 11400*****\n",
            "Train Loss: 0.6897421193789302 Test Loss: 0.6663968105920063\n",
            "Test Accuracy 0.5\n",
            "*****Iter 11500*****\n",
            "Train Loss: 0.6647133150554687 Test Loss: 0.6677552215256475\n",
            "Test Accuracy 0.5\n",
            "*****Iter 11600*****\n",
            "Train Loss: 0.6432039514236925 Test Loss: 0.6768443630837028\n",
            "Test Accuracy 0.515\n",
            "*****Iter 11700*****\n",
            "Train Loss: 0.6997189772623513 Test Loss: 0.662358490939115\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 11800*****\n",
            "Train Loss: 0.636467909904809 Test Loss: 0.6528153151402749\n",
            "Test Accuracy 0.51\n",
            "*****Iter 11900*****\n",
            "Train Loss: 0.6588399319421114 Test Loss: 0.6736030129303658\n",
            "Test Accuracy 0.51\n",
            "*****Iter 12000*****\n",
            "Train Loss: 0.675835538017509 Test Loss: 0.6720954404021809\n",
            "Test Accuracy 0.52\n",
            "*****Iter 12100*****\n",
            "Train Loss: 0.6521568263328845 Test Loss: 0.6619582531899189\n",
            "Test Accuracy 0.57\n",
            "*****Iter 12200*****\n",
            "Train Loss: 0.7152649170176346 Test Loss: 0.658730610050681\n",
            "Test Accuracy 0.505\n",
            "*****Iter 12300*****\n",
            "Train Loss: 0.640806171886652 Test Loss: 0.6572994853528612\n",
            "Test Accuracy 0.53499997\n",
            "*****Iter 12400*****\n",
            "Train Loss: 0.6369599415498044 Test Loss: 0.67025104586855\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 12500*****\n",
            "Train Loss: 0.6150529224389061 Test Loss: 0.6467673087021025\n",
            "Test Accuracy 0.515\n",
            "*****Iter 12600*****\n",
            "Train Loss: 0.6223192629810157 Test Loss: 0.6498686810684098\n",
            "Test Accuracy 0.52\n",
            "*****Iter 12700*****\n",
            "Train Loss: 0.6604845050837866 Test Loss: 0.6722146555707116\n",
            "Test Accuracy 0.53499997\n",
            "*****Iter 12800*****\n",
            "Train Loss: 0.5690566893899813 Test Loss: 0.6529580451123447\n",
            "Test Accuracy 0.515\n",
            "*****Iter 12900*****\n",
            "Train Loss: 0.5884527758971672 Test Loss: 0.6462974925671028\n",
            "Test Accuracy 0.48499998\n",
            "*****Iter 13000*****\n",
            "Train Loss: 0.6362466641486435 Test Loss: 0.6427495929642515\n",
            "Test Accuracy 0.51\n",
            "*****Iter 13100*****\n",
            "Train Loss: 0.671676913641079 Test Loss: 0.6456611809491826\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 13200*****\n",
            "Train Loss: 0.6368678559067931 Test Loss: 0.658448093188739\n",
            "Test Accuracy 0.505\n",
            "*****Iter 13300*****\n",
            "Train Loss: 0.6637929739001578 Test Loss: 0.6437455409345972\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 13400*****\n",
            "Train Loss: 0.6705860265514207 Test Loss: 0.6468093733627762\n",
            "Test Accuracy 0.48\n",
            "*****Iter 13500*****\n",
            "Train Loss: 0.6825770974103307 Test Loss: 0.6508086735284374\n",
            "Test Accuracy 0.505\n",
            "*****Iter 13600*****\n",
            "Train Loss: 0.6367705444197327 Test Loss: 0.6543343701519768\n",
            "Test Accuracy 0.51\n",
            "*****Iter 13700*****\n",
            "Train Loss: 0.6332026060203475 Test Loss: 0.6491120566730938\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 13800*****\n",
            "Train Loss: 0.6527558556572886 Test Loss: 0.6378325061183994\n",
            "Test Accuracy 0.51\n",
            "*****Iter 13900*****\n",
            "Train Loss: 0.6230595899612652 Test Loss: 0.6538251720712507\n",
            "Test Accuracy 0.5\n",
            "*****Iter 14000*****\n",
            "Train Loss: 0.6363274239421273 Test Loss: 0.6488465285083036\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 14100*****\n",
            "Train Loss: 0.672525044745214 Test Loss: 0.6412271899016978\n",
            "Test Accuracy 0.505\n",
            "*****Iter 14200*****\n",
            "Train Loss: 0.6112435412834074 Test Loss: 0.6245212540667076\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 14300*****\n",
            "Train Loss: 0.599445390719552 Test Loss: 0.6508692717544178\n",
            "Test Accuracy 0.5\n",
            "*****Iter 14400*****\n",
            "Train Loss: 0.562164508459631 Test Loss: 0.6408520272332137\n",
            "Test Accuracy 0.525\n",
            "*****Iter 14500*****\n",
            "Train Loss: 0.6134519132941278 Test Loss: 0.6311618928800223\n",
            "Test Accuracy 0.515\n",
            "*****Iter 14600*****\n",
            "Train Loss: 0.7120190424998327 Test Loss: 0.6530398536296684\n",
            "Test Accuracy 0.51\n",
            "*****Iter 14700*****\n",
            "Train Loss: 0.5541207494830473 Test Loss: 0.6420698425619309\n",
            "Test Accuracy 0.48499998\n",
            "*****Iter 14800*****\n",
            "Train Loss: 0.7289742414684922 Test Loss: 0.6389693331894162\n",
            "Test Accuracy 0.48499998\n",
            "*****Iter 14900*****\n",
            "Train Loss: 0.650484674684094 Test Loss: 0.6510847856618118\n",
            "Test Accuracy 0.5\n",
            "*****Iter 15000*****\n",
            "Train Loss: 0.7138095660486385 Test Loss: 0.625437438235633\n",
            "Test Accuracy 0.51\n",
            "*****Iter 15100*****\n",
            "Train Loss: 0.5521681139887988 Test Loss: 0.6160579091715186\n",
            "Test Accuracy 0.515\n",
            "*****Iter 15200*****\n",
            "Train Loss: 0.6468537545886761 Test Loss: 0.6413963206055066\n",
            "Test Accuracy 0.51\n",
            "*****Iter 15300*****\n",
            "Train Loss: 0.6491793496421652 Test Loss: 0.6364884939711923\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 15400*****\n",
            "Train Loss: 0.6066992752227094 Test Loss: 0.6228122404541913\n",
            "Test Accuracy 0.51\n",
            "*****Iter 15500*****\n",
            "Train Loss: 0.6932516004095319 Test Loss: 0.6250832983253717\n",
            "Test Accuracy 0.515\n",
            "*****Iter 15600*****\n",
            "Train Loss: 0.6928896562841942 Test Loss: 0.6271902107851621\n",
            "Test Accuracy 0.51\n",
            "*****Iter 15700*****\n",
            "Train Loss: 0.5514918843467456 Test Loss: 0.6472546432145484\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 15800*****\n",
            "Train Loss: 0.5935104784435907 Test Loss: 0.6355686503979858\n",
            "Test Accuracy 0.52\n",
            "*****Iter 15900*****\n",
            "Train Loss: 0.5495250980970141 Test Loss: 0.628660581563358\n",
            "Test Accuracy 0.52\n",
            "*****Iter 16000*****\n",
            "Train Loss: 0.6542524718067853 Test Loss: 0.6182904400332601\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 16100*****\n",
            "Train Loss: 0.666549545243214 Test Loss: 0.6283589931369158\n",
            "Test Accuracy 0.51\n",
            "*****Iter 16200*****\n",
            "Train Loss: 0.5422705844115967 Test Loss: 0.616596246012896\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 16300*****\n",
            "Train Loss: 0.6153938095366129 Test Loss: 0.607937394425837\n",
            "Test Accuracy 0.51\n",
            "*****Iter 16400*****\n",
            "Train Loss: 0.6007868364395108 Test Loss: 0.6238919354376965\n",
            "Test Accuracy 0.505\n",
            "*****Iter 16500*****\n",
            "Train Loss: 0.6035190646580304 Test Loss: 0.6314718082133727\n",
            "Test Accuracy 0.505\n",
            "*****Iter 16600*****\n",
            "Train Loss: 0.6501391532731873 Test Loss: 0.6144719330953946\n",
            "Test Accuracy 0.51\n",
            "*****Iter 16700*****\n",
            "Train Loss: 0.5614888360269674 Test Loss: 0.6056905731364493\n",
            "Test Accuracy 0.5\n",
            "*****Iter 16800*****\n",
            "Train Loss: 0.6124858196076275 Test Loss: 0.6136295796770274\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 16900*****\n",
            "Train Loss: 0.723432565435516 Test Loss: 0.6452142723020645\n",
            "Test Accuracy 0.51\n",
            "*****Iter 17000*****\n",
            "Train Loss: 0.6099374492000607 Test Loss: 0.6113812445216714\n",
            "Test Accuracy 0.52\n",
            "*****Iter 17100*****\n",
            "Train Loss: 0.5757109920804737 Test Loss: 0.6308511106953814\n",
            "Test Accuracy 0.51\n",
            "*****Iter 17200*****\n",
            "Train Loss: 0.5778002176406289 Test Loss: 0.6190123177767782\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 17300*****\n",
            "Train Loss: 0.5888036297075132 Test Loss: 0.626278346098773\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 17400*****\n",
            "Train Loss: 0.6419675131217559 Test Loss: 0.6015515795321602\n",
            "Test Accuracy 0.505\n",
            "*****Iter 17500*****\n",
            "Train Loss: 0.5827972896987035 Test Loss: 0.620640175039404\n",
            "Test Accuracy 0.515\n",
            "*****Iter 17600*****\n",
            "Train Loss: 0.5778381313781189 Test Loss: 0.6224499933558382\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 17700*****\n",
            "Train Loss: 0.5522645522448499 Test Loss: 0.6378190283825306\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 17800*****\n",
            "Train Loss: 0.5710187916122607 Test Loss: 0.6016584363689577\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 17900*****\n",
            "Train Loss: 0.5677029576139958 Test Loss: 0.6410817357194672\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 18000*****\n",
            "Train Loss: 0.5459879768057192 Test Loss: 0.6510773371887824\n",
            "Test Accuracy 0.5\n",
            "*****Iter 18100*****\n",
            "Train Loss: 0.5662202282279623 Test Loss: 0.6226936429079526\n",
            "Test Accuracy 0.48499998\n",
            "*****Iter 18200*****\n",
            "Train Loss: 0.567163371694619 Test Loss: 0.6275517473631151\n",
            "Test Accuracy 0.5\n",
            "*****Iter 18300*****\n",
            "Train Loss: 0.6392645937850716 Test Loss: 0.6316506692240097\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 18400*****\n",
            "Train Loss: 0.5640136783793821 Test Loss: 0.6144016282357131\n",
            "Test Accuracy 0.5\n",
            "*****Iter 18500*****\n",
            "Train Loss: 0.5726385185994936 Test Loss: 0.6191519428292955\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 18600*****\n",
            "Train Loss: 0.5565475738987402 Test Loss: 0.6016521574997433\n",
            "Test Accuracy 0.51\n",
            "*****Iter 18700*****\n",
            "Train Loss: 0.6112751656714295 Test Loss: 0.6138314425886479\n",
            "Test Accuracy 0.505\n",
            "*****Iter 18800*****\n",
            "Train Loss: 0.6523235381436194 Test Loss: 0.6278610133889893\n",
            "Test Accuracy 0.5\n",
            "*****Iter 18900*****\n",
            "Train Loss: 0.5682275289914429 Test Loss: 0.6148609621716917\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 19000*****\n",
            "Train Loss: 0.5522073737365645 Test Loss: 0.6214928043363043\n",
            "Test Accuracy 0.505\n",
            "*****Iter 19100*****\n",
            "Train Loss: 0.5953247270561519 Test Loss: 0.6303478583121154\n",
            "Test Accuracy 0.5\n",
            "*****Iter 19200*****\n",
            "Train Loss: 0.6257689228448164 Test Loss: 0.6200723803454027\n",
            "Test Accuracy 0.51\n",
            "*****Iter 19300*****\n",
            "Train Loss: 0.5283897555569865 Test Loss: 0.6416144122871185\n",
            "Test Accuracy 0.5\n",
            "*****Iter 19400*****\n",
            "Train Loss: 0.5734084614511517 Test Loss: 0.6109056570541768\n",
            "Test Accuracy 0.51\n",
            "*****Iter 19500*****\n",
            "Train Loss: 0.6066474602224332 Test Loss: 0.6193107805108025\n",
            "Test Accuracy 0.5\n",
            "*****Iter 19600*****\n",
            "Train Loss: 0.586877592349694 Test Loss: 0.626741649675338\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 19700*****\n",
            "Train Loss: 0.6170376424207049 Test Loss: 0.6207432579794568\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 19800*****\n",
            "Train Loss: 0.6305405660802279 Test Loss: 0.6277204842919497\n",
            "Test Accuracy 0.5\n",
            "*****Iter 19900*****\n",
            "Train Loss: 0.5372093640038429 Test Loss: 0.6393566451104868\n",
            "Test Accuracy 0.51\n",
            "*****Iter 20000*****\n",
            "Train Loss: 0.605372362167202 Test Loss: 0.6252002133322846\n",
            "Test Accuracy 0.505\n",
            "*****Iter 20100*****\n",
            "Train Loss: 0.5665164274491872 Test Loss: 0.6312746156806406\n",
            "Test Accuracy 0.51\n",
            "*****Iter 20200*****\n",
            "Train Loss: 0.6511227416561951 Test Loss: 0.6157587015885261\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 20300*****\n",
            "Train Loss: 0.7418243340935362 Test Loss: 0.6242791670307678\n",
            "Test Accuracy 0.48499998\n",
            "*****Iter 20400*****\n",
            "Train Loss: 0.6368969733376844 Test Loss: 0.6227559681387478\n",
            "Test Accuracy 0.5\n",
            "*****Iter 20500*****\n",
            "Train Loss: 0.6333488089620047 Test Loss: 0.6184162882362649\n",
            "Test Accuracy 0.5\n",
            "*****Iter 20600*****\n",
            "Train Loss: 0.6404456142604431 Test Loss: 0.6232764381328563\n",
            "Test Accuracy 0.5\n",
            "*****Iter 20700*****\n",
            "Train Loss: 0.7842185297599258 Test Loss: 0.6174011187166599\n",
            "Test Accuracy 0.5\n",
            "*****Iter 20800*****\n",
            "Train Loss: 0.5314178231348023 Test Loss: 0.5754954415184648\n",
            "Test Accuracy 0.5\n",
            "*****Iter 20900*****\n",
            "Train Loss: 0.6609177789497807 Test Loss: 0.6150312453277428\n",
            "Test Accuracy 0.5\n",
            "*****Iter 21000*****\n",
            "Train Loss: 0.5735146558793076 Test Loss: 0.6116262250025719\n",
            "Test Accuracy 0.51\n",
            "*****Iter 21100*****\n",
            "Train Loss: 0.6288979504169632 Test Loss: 0.6215923192280824\n",
            "Test Accuracy 0.505\n",
            "*****Iter 21200*****\n",
            "Train Loss: 0.6398195134715365 Test Loss: 0.6233091026058759\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 21300*****\n",
            "Train Loss: 0.5939240660109419 Test Loss: 0.6239996123271725\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 21400*****\n",
            "Train Loss: 0.5486669091125549 Test Loss: 0.6244737923223834\n",
            "Test Accuracy 0.5\n",
            "*****Iter 21500*****\n",
            "Train Loss: 0.61098489143302 Test Loss: 0.6296792311553046\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 21600*****\n",
            "Train Loss: 0.5168981357708162 Test Loss: 0.6304260230369098\n",
            "Test Accuracy 0.5\n",
            "*****Iter 21700*****\n",
            "Train Loss: 0.6704982267929154 Test Loss: 0.6170814054971132\n",
            "Test Accuracy 0.515\n",
            "*****Iter 21800*****\n",
            "Train Loss: 0.72275792691795 Test Loss: 0.6092125403134854\n",
            "Test Accuracy 0.505\n",
            "*****Iter 21900*****\n",
            "Train Loss: 0.5746507676140027 Test Loss: 0.6269650730895586\n",
            "Test Accuracy 0.48499998\n",
            "*****Iter 22000*****\n",
            "Train Loss: 0.5781185452852329 Test Loss: 0.6126432019229775\n",
            "Test Accuracy 0.505\n",
            "*****Iter 22100*****\n",
            "Train Loss: 0.6220487072096148 Test Loss: 0.6131729456566049\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 22200*****\n",
            "Train Loss: 0.6215383593204251 Test Loss: 0.619956055014347\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 22300*****\n",
            "Train Loss: 0.6016512794536979 Test Loss: 0.6126806871195752\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 22400*****\n",
            "Train Loss: 0.5568333953252775 Test Loss: 0.6162463132649618\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 22500*****\n",
            "Train Loss: 0.6179185071338225 Test Loss: 0.6248605247721425\n",
            "Test Accuracy 0.505\n",
            "*****Iter 22600*****\n",
            "Train Loss: 0.5809080540716032 Test Loss: 0.6226899729282073\n",
            "Test Accuracy 0.5\n",
            "*****Iter 22700*****\n",
            "Train Loss: 0.5261915629412215 Test Loss: 0.5979571008880011\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 22800*****\n",
            "Train Loss: 0.5764864635462246 Test Loss: 0.6117675988947003\n",
            "Test Accuracy 0.505\n",
            "*****Iter 22900*****\n",
            "Train Loss: 0.7588171515981141 Test Loss: 0.597871153213598\n",
            "Test Accuracy 0.515\n",
            "*****Iter 23000*****\n",
            "Train Loss: 0.654911391947536 Test Loss: 0.6253079448693999\n",
            "Test Accuracy 0.505\n",
            "*****Iter 23100*****\n",
            "Train Loss: 0.6101865333715395 Test Loss: 0.5873755285976207\n",
            "Test Accuracy 0.505\n",
            "*****Iter 23200*****\n",
            "Train Loss: 0.6115106961467518 Test Loss: 0.6061268944312839\n",
            "Test Accuracy 0.5\n",
            "*****Iter 23300*****\n",
            "Train Loss: 0.5324311120789673 Test Loss: 0.6197980631096425\n",
            "Test Accuracy 0.505\n",
            "*****Iter 23400*****\n",
            "Train Loss: 0.5472291129855229 Test Loss: 0.6149043862180256\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 23500*****\n",
            "Train Loss: 0.7305675126073652 Test Loss: 0.605899434961689\n",
            "Test Accuracy 0.5\n",
            "*****Iter 23600*****\n",
            "Train Loss: 0.6250466339712437 Test Loss: 0.6109864595932477\n",
            "Test Accuracy 0.5\n",
            "*****Iter 23700*****\n",
            "Train Loss: 0.5254797363771857 Test Loss: 0.5952119895297932\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 23800*****\n",
            "Train Loss: 0.5508772979172925 Test Loss: 0.5997379282375606\n",
            "Test Accuracy 0.505\n",
            "*****Iter 23900*****\n",
            "Train Loss: 0.5146275719033611 Test Loss: 0.628042172847978\n",
            "Test Accuracy 0.51\n",
            "*****Iter 24000*****\n",
            "Train Loss: 0.5286286040251582 Test Loss: 0.6142846841130053\n",
            "Test Accuracy 0.505\n",
            "*****Iter 24100*****\n",
            "Train Loss: 0.695437681316136 Test Loss: 0.6185520333916698\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 24200*****\n",
            "Train Loss: 0.5935854617678231 Test Loss: 0.596960201633945\n",
            "Test Accuracy 0.5\n",
            "*****Iter 24300*****\n",
            "Train Loss: 0.5710310879635454 Test Loss: 0.6067360783288397\n",
            "Test Accuracy 0.505\n",
            "*****Iter 24400*****\n",
            "Train Loss: 0.6467778957210157 Test Loss: 0.6479599928503629\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 24500*****\n",
            "Train Loss: 0.5537967584796597 Test Loss: 0.6100292280130246\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 24600*****\n",
            "Train Loss: 0.6655569421882053 Test Loss: 0.6053351510579172\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 24700*****\n",
            "Train Loss: 0.5769976259872607 Test Loss: 0.6429820097967972\n",
            "Test Accuracy 0.505\n",
            "*****Iter 24800*****\n",
            "Train Loss: 0.5431096822954942 Test Loss: 0.6036699670670029\n",
            "Test Accuracy 0.5\n",
            "*****Iter 24900*****\n",
            "Train Loss: 0.5919617169933389 Test Loss: 0.60982230358689\n",
            "Test Accuracy 0.505\n",
            "*****Iter 25000*****\n",
            "Train Loss: 0.5839391134322263 Test Loss: 0.6087219295809028\n",
            "Test Accuracy 0.505\n",
            "*****Iter 25100*****\n",
            "Train Loss: 0.6710312049907543 Test Loss: 0.6200416258220471\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 25200*****\n",
            "Train Loss: 0.5889870739717225 Test Loss: 0.6274606317509032\n",
            "Test Accuracy 0.5\n",
            "*****Iter 25300*****\n",
            "Train Loss: 0.6059200086240253 Test Loss: 0.6197416940681553\n",
            "Test Accuracy 0.5\n",
            "*****Iter 25400*****\n",
            "Train Loss: 0.6600023478029016 Test Loss: 0.625800308742778\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 25500*****\n",
            "Train Loss: 0.5480231213095976 Test Loss: 0.6062732822593448\n",
            "Test Accuracy 0.505\n",
            "*****Iter 25600*****\n",
            "Train Loss: 0.5774711624232793 Test Loss: 0.6143724860114842\n",
            "Test Accuracy 0.5\n",
            "*****Iter 25700*****\n",
            "Train Loss: 0.6315723945934764 Test Loss: 0.6104297210468019\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 25800*****\n",
            "Train Loss: 0.568648057419523 Test Loss: 0.6159585421151039\n",
            "Test Accuracy 0.5\n",
            "*****Iter 25900*****\n",
            "Train Loss: 0.7420612553905812 Test Loss: 0.6118076734388282\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 26000*****\n",
            "Train Loss: 0.6919430870446348 Test Loss: 0.6072342162800449\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 26100*****\n",
            "Train Loss: 0.5477695203843851 Test Loss: 0.6162870636410257\n",
            "Test Accuracy 0.5\n",
            "*****Iter 26200*****\n",
            "Train Loss: 0.569267734712195 Test Loss: 0.618439115715388\n",
            "Test Accuracy 0.505\n",
            "*****Iter 26300*****\n",
            "Train Loss: 0.5926248872499329 Test Loss: 0.6126979620080715\n",
            "Test Accuracy 0.51\n",
            "*****Iter 26400*****\n",
            "Train Loss: 0.5622083845104839 Test Loss: 0.6257050261888081\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 26500*****\n",
            "Train Loss: 0.6706199553960106 Test Loss: 0.6092477625304707\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 26600*****\n",
            "Train Loss: 0.5566918758668642 Test Loss: 0.6217264819571088\n",
            "Test Accuracy 0.505\n",
            "*****Iter 26700*****\n",
            "Train Loss: 0.6172857517652659 Test Loss: 0.614476799253715\n",
            "Test Accuracy 0.5\n",
            "*****Iter 26800*****\n",
            "Train Loss: 0.6154440164219892 Test Loss: 0.6481562900512502\n",
            "Test Accuracy 0.52\n",
            "*****Iter 26900*****\n",
            "Train Loss: 0.5550299871025004 Test Loss: 0.6099691184090233\n",
            "Test Accuracy 0.52\n",
            "*****Iter 27000*****\n",
            "Train Loss: 0.5317244880720295 Test Loss: 0.6124137804414664\n",
            "Test Accuracy 0.51\n",
            "*****Iter 27100*****\n",
            "Train Loss: 0.6657886058114855 Test Loss: 0.6181722890959329\n",
            "Test Accuracy 0.5\n",
            "*****Iter 27200*****\n",
            "Train Loss: 0.6172848087278098 Test Loss: 0.6470565526744323\n",
            "Test Accuracy 0.5\n",
            "*****Iter 27300*****\n",
            "Train Loss: 0.5626156002572316 Test Loss: 0.5841784997149003\n",
            "Test Accuracy 0.51\n",
            "*****Iter 27400*****\n",
            "Train Loss: 0.6774486775446924 Test Loss: 0.6279568384731581\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 27500*****\n",
            "Train Loss: 0.6198354741329695 Test Loss: 0.6166203264698786\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 27600*****\n",
            "Train Loss: 0.6582229978977807 Test Loss: 0.632961292972005\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 27700*****\n",
            "Train Loss: 0.527411702037881 Test Loss: 0.6149791017878135\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 27800*****\n",
            "Train Loss: 0.5987670791994333 Test Loss: 0.6120784494411715\n",
            "Test Accuracy 0.51\n",
            "*****Iter 27900*****\n",
            "Train Loss: 0.6402689806516264 Test Loss: 0.6301553859421525\n",
            "Test Accuracy 0.5\n",
            "*****Iter 28000*****\n",
            "Train Loss: 0.612253656897586 Test Loss: 0.6176842261732407\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 28100*****\n",
            "Train Loss: 0.5690723968304496 Test Loss: 0.6117786580076606\n",
            "Test Accuracy 0.525\n",
            "*****Iter 28200*****\n",
            "Train Loss: 0.6021869353914138 Test Loss: 0.6310002135463907\n",
            "Test Accuracy 0.515\n",
            "*****Iter 28300*****\n",
            "Train Loss: 0.5518253621830453 Test Loss: 0.6097584126272607\n",
            "Test Accuracy 0.505\n",
            "*****Iter 28400*****\n",
            "Train Loss: 0.6702333308726338 Test Loss: 0.6341908987061555\n",
            "Test Accuracy 0.5\n",
            "*****Iter 28500*****\n",
            "Train Loss: 0.6369103043076834 Test Loss: 0.6345755106288425\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 28600*****\n",
            "Train Loss: 0.5712210728081886 Test Loss: 0.621464488785332\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 28700*****\n",
            "Train Loss: 0.5839929856432491 Test Loss: 0.5932146602305414\n",
            "Test Accuracy 0.51\n",
            "*****Iter 28800*****\n",
            "Train Loss: 0.5910918693484564 Test Loss: 0.6393940261370971\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 28900*****\n",
            "Train Loss: 0.57370040693786 Test Loss: 0.6226565781373765\n",
            "Test Accuracy 0.51\n",
            "*****Iter 29000*****\n",
            "Train Loss: 0.6009251920372793 Test Loss: 0.6050334976097095\n",
            "Test Accuracy 0.5\n",
            "*****Iter 29100*****\n",
            "Train Loss: 0.6636063834225574 Test Loss: 0.6258586484339673\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 29200*****\n",
            "Train Loss: 0.5816219941932363 Test Loss: 0.6129320547636405\n",
            "Test Accuracy 0.505\n",
            "*****Iter 29300*****\n",
            "Train Loss: 0.6072509754451403 Test Loss: 0.6066103020844213\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 29400*****\n",
            "Train Loss: 0.555372874797893 Test Loss: 0.6098960703600188\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 29500*****\n",
            "Train Loss: 0.8123249106065487 Test Loss: 0.6076357225194442\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 29600*****\n",
            "Train Loss: 0.7396120404068967 Test Loss: 0.5962902480123755\n",
            "Test Accuracy 0.505\n",
            "*****Iter 29700*****\n",
            "Train Loss: 0.5669799094724031 Test Loss: 0.6213128559066027\n",
            "Test Accuracy 0.505\n",
            "*****Iter 29800*****\n",
            "Train Loss: 0.5985209129693061 Test Loss: 0.6117078139609936\n",
            "Test Accuracy 0.505\n",
            "*****Iter 29900*****\n",
            "Train Loss: 0.5746021767066267 Test Loss: 0.6187648772710652\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 30000*****\n",
            "Train Loss: 0.6124298544058888 Test Loss: 0.6015426319869008\n",
            "Test Accuracy 0.505\n",
            "*****Iter 30100*****\n",
            "Train Loss: 0.6671115510466734 Test Loss: 0.6149785786770693\n",
            "Test Accuracy 0.505\n",
            "*****Iter 30200*****\n",
            "Train Loss: 0.6474451307817084 Test Loss: 0.6035506434108519\n",
            "Test Accuracy 0.5\n",
            "*****Iter 30300*****\n",
            "Train Loss: 0.6078799468665599 Test Loss: 0.5995729400874772\n",
            "Test Accuracy 0.505\n",
            "*****Iter 30400*****\n",
            "Train Loss: 0.5689190147007395 Test Loss: 0.6062825823319103\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 30500*****\n",
            "Train Loss: 0.6270229755286261 Test Loss: 0.6008365695460298\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 30600*****\n",
            "Train Loss: 0.6714216381517346 Test Loss: 0.6023552612268972\n",
            "Test Accuracy 0.5\n",
            "*****Iter 30700*****\n",
            "Train Loss: 0.6533064811346456 Test Loss: 0.5934630824552904\n",
            "Test Accuracy 0.505\n",
            "*****Iter 30800*****\n",
            "Train Loss: 0.5965177486968827 Test Loss: 0.6142842280164525\n",
            "Test Accuracy 0.5\n",
            "*****Iter 30900*****\n",
            "Train Loss: 0.6594524874602765 Test Loss: 0.630576816293379\n",
            "Test Accuracy 0.5\n",
            "*****Iter 31000*****\n",
            "Train Loss: 0.6803011548845461 Test Loss: 0.6167138427863994\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 31100*****\n",
            "Train Loss: 0.5517589916798613 Test Loss: 0.5965506182759148\n",
            "Test Accuracy 0.5\n",
            "*****Iter 31200*****\n",
            "Train Loss: 0.6867085114163074 Test Loss: 0.6104737294266462\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 31300*****\n",
            "Train Loss: 0.706384895541305 Test Loss: 0.6098090319375519\n",
            "Test Accuracy 0.5\n",
            "*****Iter 31400*****\n",
            "Train Loss: 0.732475917465564 Test Loss: 0.6168396070154184\n",
            "Test Accuracy 0.5\n",
            "*****Iter 31500*****\n",
            "Train Loss: 0.6992123494758431 Test Loss: 0.6297412816098141\n",
            "Test Accuracy 0.51\n",
            "*****Iter 31600*****\n",
            "Train Loss: 0.6374819533879688 Test Loss: 0.615449706862839\n",
            "Test Accuracy 0.5\n",
            "*****Iter 31700*****\n",
            "Train Loss: 0.6180266399265575 Test Loss: 0.6198835244526403\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 31800*****\n",
            "Train Loss: 0.6553434645320522 Test Loss: 0.6063315815380168\n",
            "Test Accuracy 0.5\n",
            "*****Iter 31900*****\n",
            "Train Loss: 0.5989309826180529 Test Loss: 0.6238795077018073\n",
            "Test Accuracy 0.505\n",
            "*****Iter 32000*****\n",
            "Train Loss: 0.7168964173830688 Test Loss: 0.6333049061953568\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 32100*****\n",
            "Train Loss: 0.623432692711404 Test Loss: 0.6235824594971695\n",
            "Test Accuracy 0.5\n",
            "*****Iter 32200*****\n",
            "Train Loss: 0.5981180429518839 Test Loss: 0.619569502932457\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 32300*****\n",
            "Train Loss: 0.5640815289459091 Test Loss: 0.5975761456852968\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 32400*****\n",
            "Train Loss: 0.656616553751519 Test Loss: 0.6232766639401249\n",
            "Test Accuracy 0.505\n",
            "*****Iter 32500*****\n",
            "Train Loss: 0.5784349901530268 Test Loss: 0.6165635633045156\n",
            "Test Accuracy 0.505\n",
            "*****Iter 32600*****\n",
            "Train Loss: 0.640663967872523 Test Loss: 0.6117708522270183\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 32700*****\n",
            "Train Loss: 0.6199194211625176 Test Loss: 0.5997106064914454\n",
            "Test Accuracy 0.505\n",
            "*****Iter 32800*****\n",
            "Train Loss: 0.6801415349606827 Test Loss: 0.600465638290054\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 32900*****\n",
            "Train Loss: 0.6023282384970798 Test Loss: 0.6018660317203122\n",
            "Test Accuracy 0.5\n",
            "*****Iter 33000*****\n",
            "Train Loss: 0.6183589454933465 Test Loss: 0.6237895737031147\n",
            "Test Accuracy 0.5\n",
            "*****Iter 33100*****\n",
            "Train Loss: 0.6124721917985267 Test Loss: 0.6125700212876684\n",
            "Test Accuracy 0.5\n",
            "*****Iter 33200*****\n",
            "Train Loss: 0.6190627058390419 Test Loss: 0.6071084909692277\n",
            "Test Accuracy 0.5\n",
            "*****Iter 33300*****\n",
            "Train Loss: 0.556659917196884 Test Loss: 0.6143919780517743\n",
            "Test Accuracy 0.51\n",
            "*****Iter 33400*****\n",
            "Train Loss: 0.6557117113393254 Test Loss: 0.6075732626695356\n",
            "Test Accuracy 0.505\n",
            "*****Iter 33500*****\n",
            "Train Loss: 0.5865885452857 Test Loss: 0.6050468799441969\n",
            "Test Accuracy 0.505\n",
            "*****Iter 33600*****\n",
            "Train Loss: 0.5615282340745678 Test Loss: 0.5942152279412005\n",
            "Test Accuracy 0.51\n",
            "*****Iter 33700*****\n",
            "Train Loss: 0.5358925526942251 Test Loss: 0.6052494299562374\n",
            "Test Accuracy 0.505\n",
            "*****Iter 33800*****\n",
            "Train Loss: 0.6113202500182524 Test Loss: 0.6258956039759568\n",
            "Test Accuracy 0.505\n",
            "*****Iter 33900*****\n",
            "Train Loss: 0.5164968622279451 Test Loss: 0.611362579101353\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 34000*****\n",
            "Train Loss: 0.6631320254138391 Test Loss: 0.6319972248874677\n",
            "Test Accuracy 0.505\n",
            "*****Iter 34100*****\n",
            "Train Loss: 0.6220590848533902 Test Loss: 0.6150468703626398\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 34200*****\n",
            "Train Loss: 0.5963229834044483 Test Loss: 0.6349793836742821\n",
            "Test Accuracy 0.51\n",
            "*****Iter 34300*****\n",
            "Train Loss: 0.596329175152579 Test Loss: 0.6018583241918812\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 34400*****\n",
            "Train Loss: 0.5371126270367248 Test Loss: 0.6043129673904293\n",
            "Test Accuracy 0.505\n",
            "*****Iter 34500*****\n",
            "Train Loss: 0.5736586367234366 Test Loss: 0.6196665518979384\n",
            "Test Accuracy 0.48499998\n",
            "*****Iter 34600*****\n",
            "Train Loss: 0.6420200711613084 Test Loss: 0.59714794876653\n",
            "Test Accuracy 0.51\n",
            "*****Iter 34700*****\n",
            "Train Loss: 0.6576609719962163 Test Loss: 0.6084116476764715\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 34800*****\n",
            "Train Loss: 0.6340405442847441 Test Loss: 0.6360778544356639\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 34900*****\n",
            "Train Loss: 0.6231186107215665 Test Loss: 0.6041753208862275\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 35000*****\n",
            "Train Loss: 0.6786844152681795 Test Loss: 0.6231631187761172\n",
            "Test Accuracy 0.51\n",
            "*****Iter 35100*****\n",
            "Train Loss: 0.7182633743796032 Test Loss: 0.6075088746152438\n",
            "Test Accuracy 0.515\n",
            "*****Iter 35200*****\n",
            "Train Loss: 0.5078000356623082 Test Loss: 0.6274149076116927\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 35300*****\n",
            "Train Loss: 0.6130570711558319 Test Loss: 0.6134349484725043\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 35400*****\n",
            "Train Loss: 0.5075635246652874 Test Loss: 0.6236441691446033\n",
            "Test Accuracy 0.505\n",
            "*****Iter 35500*****\n",
            "Train Loss: 0.8089343807077967 Test Loss: 0.6091933156181415\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 35600*****\n",
            "Train Loss: 0.5509895641603801 Test Loss: 0.6198505498200644\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 35700*****\n",
            "Train Loss: 0.5687468933304132 Test Loss: 0.5998954721315553\n",
            "Test Accuracy 0.52\n",
            "*****Iter 35800*****\n",
            "Train Loss: 0.6034975627487711 Test Loss: 0.6044914586342046\n",
            "Test Accuracy 0.5\n",
            "*****Iter 35900*****\n",
            "Train Loss: 0.6264387485493823 Test Loss: 0.6115004046963336\n",
            "Test Accuracy 0.5\n",
            "*****Iter 36000*****\n",
            "Train Loss: 0.771117793670328 Test Loss: 0.621988447229464\n",
            "Test Accuracy 0.515\n",
            "*****Iter 36100*****\n",
            "Train Loss: 0.6018825579165181 Test Loss: 0.5910794491841193\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 36200*****\n",
            "Train Loss: 0.670338973356138 Test Loss: 0.6107325777703698\n",
            "Test Accuracy 0.505\n",
            "*****Iter 36300*****\n",
            "Train Loss: 0.6203221484027495 Test Loss: 0.608976920460547\n",
            "Test Accuracy 0.5\n",
            "*****Iter 36400*****\n",
            "Train Loss: 0.6625672391382977 Test Loss: 0.6137133902031148\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 36500*****\n",
            "Train Loss: 0.6398654276026718 Test Loss: 0.6026977082012208\n",
            "Test Accuracy 0.51\n",
            "*****Iter 36600*****\n",
            "Train Loss: 0.6048159623911822 Test Loss: 0.5857228157517618\n",
            "Test Accuracy 0.5\n",
            "*****Iter 36700*****\n",
            "Train Loss: 0.5180798330936476 Test Loss: 0.6189283518391558\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 36800*****\n",
            "Train Loss: 0.6576327661769028 Test Loss: 0.6101883177692811\n",
            "Test Accuracy 0.505\n",
            "*****Iter 36900*****\n",
            "Train Loss: 0.5780537470718627 Test Loss: 0.6137771512155631\n",
            "Test Accuracy 0.505\n",
            "*****Iter 37000*****\n",
            "Train Loss: 0.7186289448591197 Test Loss: 0.6294717776498081\n",
            "Test Accuracy 0.5\n",
            "*****Iter 37100*****\n",
            "Train Loss: 0.6202819415193517 Test Loss: 0.6462914521324665\n",
            "Test Accuracy 0.52\n",
            "*****Iter 37200*****\n",
            "Train Loss: 0.7038188023684029 Test Loss: 0.6055988147102509\n",
            "Test Accuracy 0.5\n",
            "*****Iter 37300*****\n",
            "Train Loss: 0.6455117448735113 Test Loss: 0.6028990110974075\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 37400*****\n",
            "Train Loss: 0.5102326787125548 Test Loss: 0.6293559582975526\n",
            "Test Accuracy 0.5\n",
            "*****Iter 37500*****\n",
            "Train Loss: 0.54912485393554 Test Loss: 0.6102523605443274\n",
            "Test Accuracy 0.5\n",
            "*****Iter 37600*****\n",
            "Train Loss: 0.6620954469919269 Test Loss: 0.6253794403411138\n",
            "Test Accuracy 0.51\n",
            "*****Iter 37700*****\n",
            "Train Loss: 0.5417042593918033 Test Loss: 0.5838464598712905\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 37800*****\n",
            "Train Loss: 0.6077915813540136 Test Loss: 0.6069663336383513\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 37900*****\n",
            "Train Loss: 0.6349787342441775 Test Loss: 0.6054610392496464\n",
            "Test Accuracy 0.5\n",
            "*****Iter 38000*****\n",
            "Train Loss: 0.5899492959366555 Test Loss: 0.617505229499748\n",
            "Test Accuracy 0.505\n",
            "*****Iter 38100*****\n",
            "Train Loss: 0.8301760759204626 Test Loss: 0.6161124904853463\n",
            "Test Accuracy 0.505\n",
            "*****Iter 38200*****\n",
            "Train Loss: 0.5943756521774125 Test Loss: 0.610375148907214\n",
            "Test Accuracy 0.505\n",
            "*****Iter 38300*****\n",
            "Train Loss: 0.6515732561011873 Test Loss: 0.6171150191332906\n",
            "Test Accuracy 0.505\n",
            "*****Iter 38400*****\n",
            "Train Loss: 0.5685315956125123 Test Loss: 0.6193503096823347\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 38500*****\n",
            "Train Loss: 0.6546951843340878 Test Loss: 0.614707477099036\n",
            "Test Accuracy 0.5\n",
            "*****Iter 38600*****\n",
            "Train Loss: 0.7742891506063714 Test Loss: 0.5848036506697403\n",
            "Test Accuracy 0.505\n",
            "*****Iter 38700*****\n",
            "Train Loss: 0.6525136801735947 Test Loss: 0.603025875119337\n",
            "Test Accuracy 0.505\n",
            "*****Iter 38800*****\n",
            "Train Loss: 0.5894586634845447 Test Loss: 0.6164053631760438\n",
            "Test Accuracy 0.51\n",
            "*****Iter 38900*****\n",
            "Train Loss: 0.8490126766264439 Test Loss: 0.6108208599906271\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 39000*****\n",
            "Train Loss: 0.5774247534900496 Test Loss: 0.6120870711378705\n",
            "Test Accuracy 0.5\n",
            "*****Iter 39100*****\n",
            "Train Loss: 0.5952957333132041 Test Loss: 0.6020228992131781\n",
            "Test Accuracy 0.5\n",
            "*****Iter 39200*****\n",
            "Train Loss: 0.5785511900356717 Test Loss: 0.6167927685181676\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 39300*****\n",
            "Train Loss: 0.675903531547533 Test Loss: 0.604874014174764\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 39400*****\n",
            "Train Loss: 0.5413334984021051 Test Loss: 0.5962013242965505\n",
            "Test Accuracy 0.5\n",
            "*****Iter 39500*****\n",
            "Train Loss: 0.5826887214530831 Test Loss: 0.6102019566136961\n",
            "Test Accuracy 0.5\n",
            "*****Iter 39600*****\n",
            "Train Loss: 0.6129897549078578 Test Loss: 0.6108355808820287\n",
            "Test Accuracy 0.48499998\n",
            "*****Iter 39700*****\n",
            "Train Loss: 0.6932263271324786 Test Loss: 0.620684561579059\n",
            "Test Accuracy 0.48499998\n",
            "*****Iter 39800*****\n",
            "Train Loss: 0.583516546611591 Test Loss: 0.6270706315669358\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 39900*****\n",
            "Train Loss: 0.566788405509719 Test Loss: 0.5977553602956224\n",
            "Test Accuracy 0.505\n",
            "*****Iter 40000*****\n",
            "Train Loss: 0.6113393426625833 Test Loss: 0.6146639107937799\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 40100*****\n",
            "Train Loss: 0.6530596745152053 Test Loss: 0.5798813050305155\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 40200*****\n",
            "Train Loss: 0.5152559771898906 Test Loss: 0.6198747095049215\n",
            "Test Accuracy 0.51\n",
            "*****Iter 40300*****\n",
            "Train Loss: 0.5421540127341499 Test Loss: 0.5976572135763946\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 40400*****\n",
            "Train Loss: 0.5738435714308139 Test Loss: 0.6034283452810848\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 40500*****\n",
            "Train Loss: 0.6694210919704346 Test Loss: 0.6060662104429274\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 40600*****\n",
            "Train Loss: 0.6024946595933698 Test Loss: 0.6109306727839934\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 40700*****\n",
            "Train Loss: 0.6492756618268207 Test Loss: 0.6137186948186668\n",
            "Test Accuracy 0.505\n",
            "*****Iter 40800*****\n",
            "Train Loss: 0.5880827199375969 Test Loss: 0.5965125899204994\n",
            "Test Accuracy 0.5\n",
            "*****Iter 40900*****\n",
            "Train Loss: 0.5363696541217804 Test Loss: 0.6154549587195378\n",
            "Test Accuracy 0.505\n",
            "*****Iter 41000*****\n",
            "Train Loss: 0.6289437991297859 Test Loss: 0.5988909628710175\n",
            "Test Accuracy 0.515\n",
            "*****Iter 41100*****\n",
            "Train Loss: 0.6115432316347125 Test Loss: 0.6148305822985877\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 41200*****\n",
            "Train Loss: 0.5843934481625954 Test Loss: 0.6354450048716875\n",
            "Test Accuracy 0.5\n",
            "*****Iter 41300*****\n",
            "Train Loss: 0.508950719793037 Test Loss: 0.6033602436735931\n",
            "Test Accuracy 0.5\n",
            "*****Iter 41400*****\n",
            "Train Loss: 0.6144030193507951 Test Loss: 0.6126250863015026\n",
            "Test Accuracy 0.505\n",
            "*****Iter 41500*****\n",
            "Train Loss: 0.5203743859707032 Test Loss: 0.5845175917846318\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 41600*****\n",
            "Train Loss: 0.564908197582424 Test Loss: 0.6135557461781563\n",
            "Test Accuracy 0.505\n",
            "*****Iter 41700*****\n",
            "Train Loss: 0.6101508165204805 Test Loss: 0.6260344099807182\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 41800*****\n",
            "Train Loss: 0.5880397757662514 Test Loss: 0.6127558046887418\n",
            "Test Accuracy 0.5\n",
            "*****Iter 41900*****\n",
            "Train Loss: 0.6018673322803867 Test Loss: 0.6013123034453823\n",
            "Test Accuracy 0.5\n",
            "*****Iter 42000*****\n",
            "Train Loss: 0.6415415053156153 Test Loss: 0.6050605566285068\n",
            "Test Accuracy 0.5\n",
            "*****Iter 42100*****\n",
            "Train Loss: 0.5674261363285495 Test Loss: 0.6142319503232136\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 42200*****\n",
            "Train Loss: 0.691870143133201 Test Loss: 0.598431803934077\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 42300*****\n",
            "Train Loss: 0.5695764949713089 Test Loss: 0.6062751881145081\n",
            "Test Accuracy 0.5\n",
            "*****Iter 42400*****\n",
            "Train Loss: 0.5238826409750441 Test Loss: 0.6027123181800178\n",
            "Test Accuracy 0.5\n",
            "*****Iter 42500*****\n",
            "Train Loss: 0.7015561049923349 Test Loss: 0.608193340257869\n",
            "Test Accuracy 0.505\n",
            "*****Iter 42600*****\n",
            "Train Loss: 0.5062825049588682 Test Loss: 0.6270040437395297\n",
            "Test Accuracy 0.5\n",
            "*****Iter 42700*****\n",
            "Train Loss: 0.6284167999917827 Test Loss: 0.6026382179423173\n",
            "Test Accuracy 0.5\n",
            "*****Iter 42800*****\n",
            "Train Loss: 0.5650746760009859 Test Loss: 0.621062166093657\n",
            "Test Accuracy 0.5\n",
            "*****Iter 42900*****\n",
            "Train Loss: 0.6618482074177798 Test Loss: 0.624603679629841\n",
            "Test Accuracy 0.5\n",
            "*****Iter 43000*****\n",
            "Train Loss: 0.7309232841125777 Test Loss: 0.6065934108572612\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 43100*****\n",
            "Train Loss: 0.6279053416028546 Test Loss: 0.5913543943256901\n",
            "Test Accuracy 0.5\n",
            "*****Iter 43200*****\n",
            "Train Loss: 0.6467955311712075 Test Loss: 0.6125203908283785\n",
            "Test Accuracy 0.505\n",
            "*****Iter 43300*****\n",
            "Train Loss: 0.7017666560078997 Test Loss: 0.6234788779237215\n",
            "Test Accuracy 0.5\n",
            "*****Iter 43400*****\n",
            "Train Loss: 0.5538565126698849 Test Loss: 0.583265175544835\n",
            "Test Accuracy 0.5\n",
            "*****Iter 43500*****\n",
            "Train Loss: 0.5894917975565868 Test Loss: 0.5968344644549357\n",
            "Test Accuracy 0.505\n",
            "*****Iter 43600*****\n",
            "Train Loss: 0.6432045658952656 Test Loss: 0.6252857191173474\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 43700*****\n",
            "Train Loss: 0.5566381575359104 Test Loss: 0.5830555121661604\n",
            "Test Accuracy 0.5\n",
            "*****Iter 43800*****\n",
            "Train Loss: 0.5476223322344891 Test Loss: 0.6169134218231066\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 43900*****\n",
            "Train Loss: 0.6563787589225152 Test Loss: 0.6041951806504179\n",
            "Test Accuracy 0.505\n",
            "*****Iter 44000*****\n",
            "Train Loss: 0.5984939680141959 Test Loss: 0.602068282875075\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 44100*****\n",
            "Train Loss: 0.6982173916345644 Test Loss: 0.605943491619997\n",
            "Test Accuracy 0.505\n",
            "*****Iter 44200*****\n",
            "Train Loss: 0.6974375543629847 Test Loss: 0.5761811129772415\n",
            "Test Accuracy 0.505\n",
            "*****Iter 44300*****\n",
            "Train Loss: 0.5995741416478957 Test Loss: 0.610882863709693\n",
            "Test Accuracy 0.505\n",
            "*****Iter 44400*****\n",
            "Train Loss: 0.6057477850825143 Test Loss: 0.6147119344117148\n",
            "Test Accuracy 0.505\n",
            "*****Iter 44500*****\n",
            "Train Loss: 0.6367749009895363 Test Loss: 0.6025055674535581\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 44600*****\n",
            "Train Loss: 0.6277145225606091 Test Loss: 0.6200116147607336\n",
            "Test Accuracy 0.5\n",
            "*****Iter 44700*****\n",
            "Train Loss: 0.5678390036754557 Test Loss: 0.612708063168304\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 44800*****\n",
            "Train Loss: 0.7038233612578164 Test Loss: 0.6143341702164986\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 44900*****\n",
            "Train Loss: 0.6049741694205245 Test Loss: 0.6288896744419632\n",
            "Test Accuracy 0.48\n",
            "*****Iter 45000*****\n",
            "Train Loss: 0.5918660671372749 Test Loss: 0.5969437895777384\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 45100*****\n",
            "Train Loss: 0.5535181628499117 Test Loss: 0.625428814288116\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 45200*****\n",
            "Train Loss: 0.6134877038155082 Test Loss: 0.6117831546643032\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 45300*****\n",
            "Train Loss: 0.6243034242938826 Test Loss: 0.5859023158884726\n",
            "Test Accuracy 0.505\n",
            "*****Iter 45400*****\n",
            "Train Loss: 0.6139609264885983 Test Loss: 0.6000474948323435\n",
            "Test Accuracy 0.505\n",
            "*****Iter 45500*****\n",
            "Train Loss: 0.6497121935180452 Test Loss: 0.6094317802478864\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 45600*****\n",
            "Train Loss: 0.6720918577866541 Test Loss: 0.6283557548260302\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 45700*****\n",
            "Train Loss: 0.5913300311546905 Test Loss: 0.5976644868025803\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 45800*****\n",
            "Train Loss: 0.607583947202329 Test Loss: 0.6122387089688781\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 45900*****\n",
            "Train Loss: 0.6875478019558647 Test Loss: 0.6152856978531673\n",
            "Test Accuracy 0.5\n",
            "*****Iter 46000*****\n",
            "Train Loss: 0.5830237888239083 Test Loss: 0.6206285739800623\n",
            "Test Accuracy 0.505\n",
            "*****Iter 46100*****\n",
            "Train Loss: 0.5605179489113132 Test Loss: 0.6064871448113252\n",
            "Test Accuracy 0.51\n",
            "*****Iter 46200*****\n",
            "Train Loss: 0.6030850522289946 Test Loss: 0.5993141680469202\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 46300*****\n",
            "Train Loss: 0.5940144893236985 Test Loss: 0.6344651693048782\n",
            "Test Accuracy 0.515\n",
            "*****Iter 46400*****\n",
            "Train Loss: 0.5610714758465569 Test Loss: 0.6001825537885292\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 46500*****\n",
            "Train Loss: 0.6097165745620696 Test Loss: 0.5972677818103709\n",
            "Test Accuracy 0.505\n",
            "*****Iter 46600*****\n",
            "Train Loss: 0.664277894305343 Test Loss: 0.6060385355165245\n",
            "Test Accuracy 0.505\n",
            "*****Iter 46700*****\n",
            "Train Loss: 0.5939498393326517 Test Loss: 0.6134461312241422\n",
            "Test Accuracy 0.5\n",
            "*****Iter 46800*****\n",
            "Train Loss: 0.543020758630206 Test Loss: 0.6058513374923403\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 46900*****\n",
            "Train Loss: 0.6120772818162974 Test Loss: 0.5899790448469757\n",
            "Test Accuracy 0.5\n",
            "*****Iter 47000*****\n",
            "Train Loss: 0.5323781664790199 Test Loss: 0.6135096294046483\n",
            "Test Accuracy 0.5\n",
            "*****Iter 47100*****\n",
            "Train Loss: 0.5425984044401678 Test Loss: 0.5813375911952351\n",
            "Test Accuracy 0.5\n",
            "*****Iter 47200*****\n",
            "Train Loss: 0.6190708335992737 Test Loss: 0.5804475894336627\n",
            "Test Accuracy 0.51\n",
            "*****Iter 47300*****\n",
            "Train Loss: 0.6884059501323714 Test Loss: 0.6049253508568759\n",
            "Test Accuracy 0.51\n",
            "*****Iter 47400*****\n",
            "Train Loss: 0.5693311089782993 Test Loss: 0.5810448332893128\n",
            "Test Accuracy 0.48499998\n",
            "*****Iter 47500*****\n",
            "Train Loss: 0.5661699162328757 Test Loss: 0.610927418430116\n",
            "Test Accuracy 0.515\n",
            "*****Iter 47600*****\n",
            "Train Loss: 0.6405174894158088 Test Loss: 0.6114833206204257\n",
            "Test Accuracy 0.505\n",
            "*****Iter 47700*****\n",
            "Train Loss: 0.5149128616670358 Test Loss: 0.60638979530786\n",
            "Test Accuracy 0.48499998\n",
            "*****Iter 47800*****\n",
            "Train Loss: 0.5465747761314894 Test Loss: 0.5901108580765229\n",
            "Test Accuracy 0.505\n",
            "*****Iter 47900*****\n",
            "Train Loss: 0.7133681030600201 Test Loss: 0.6320757813606174\n",
            "Test Accuracy 0.5\n",
            "*****Iter 48000*****\n",
            "Train Loss: 0.535746144336116 Test Loss: 0.6179752758610263\n",
            "Test Accuracy 0.51\n",
            "*****Iter 48100*****\n",
            "Train Loss: 0.5578382505146569 Test Loss: 0.6350039896058143\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 48200*****\n",
            "Train Loss: 0.6725323274404289 Test Loss: 0.6233552658193566\n",
            "Test Accuracy 0.48499998\n",
            "*****Iter 48300*****\n",
            "Train Loss: 0.61950629108187 Test Loss: 0.6021245566016894\n",
            "Test Accuracy 0.505\n",
            "*****Iter 48400*****\n",
            "Train Loss: 0.5733659888789759 Test Loss: 0.6030381977827509\n",
            "Test Accuracy 0.49499997\n",
            "*****Iter 48500*****\n",
            "Train Loss: 0.7548116381103682 Test Loss: 0.6261737672501372\n",
            "Test Accuracy 0.5\n",
            "*****Iter 48600*****\n",
            "Train Loss: 0.5552781415069727 Test Loss: 0.599126763311784\n",
            "Test Accuracy 0.505\n",
            "*****Iter 48700*****\n",
            "Train Loss: 0.6050375626699065 Test Loss: 0.6082012913763072\n",
            "Test Accuracy 0.5\n",
            "*****Iter 48800*****\n",
            "Train Loss: 0.5665038974334429 Test Loss: 0.6079616094268787\n",
            "Test Accuracy 0.48999998\n",
            "*****Iter 48900*****\n",
            "Train Loss: 0.5682911174020506 Test Loss: 0.6035048858686478\n",
            "Test Accuracy 0.505\n",
            "*****Iter 49000*****\n",
            "Train Loss: 0.6254651046804159 Test Loss: 0.589750952238614\n",
            "Test Accuracy 0.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-55973d937c07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK_plus_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-7c28b4732e76>\u001b[0m in \u001b[0;36msample_batch\u001b[0;34m(self, batch_type, batch_size)\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0msampled_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m       images_labels = get_images(\n\u001b[0;32m--> 109\u001b[0;31m         sampled_paths, np.eye(self.num_classes), self.num_samples_per_class, False)\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m       \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/twodim_base.py\u001b[0m in \u001b[0;36meye\u001b[0;34m(N, M, k, dtype, order)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mM\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}